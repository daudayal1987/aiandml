{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bhffKB52E3Xk",
        "outputId": "905308b0-ed52-480f-b1da-a0470b17a38e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.11/dist-packages (4.14.0)\n",
            "Requirement already satisfied: langchain-openai in /usr/local/lib/python3.11/dist-packages (0.3.30)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.74)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: dnspython<3.0.0,>=1.16.0 in /usr/local/lib/python3.11/dist-packages (from pymongo) (2.7.0)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.99.9 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.99.9)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (8.5.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (25.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.99.9->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken<1,>=0.7->langchain-openai) (2024.11.6)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain pymongo langchain-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "95cHKoMGFDCA"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pymongo\n",
        "import json\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain.callbacks.tracers import ConsoleCallbackHandler\n",
        "from pymongo.mongo_client import MongoClient\n",
        "from pymongo.server_api import ServerApi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "jPV8mWX5VI5X"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPEN_AI_KEY')\n",
        "os.environ.pop('OPENAI_ORGANIZATION', None)\n",
        "os.environ.pop('OPENAI_PROJECT_ID', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "Yg74M1dRGQj2"
      },
      "outputs": [],
      "source": [
        "# --- MongoDB Atlas Configuration ---\n",
        "MONGO_URI = userdata.get('MONGO_ATLAS_URI')\n",
        "DB_NAME = \"organization_db\"\n",
        "COLLECTION_NAME = \"employees\"\n",
        "\n",
        "def get_mongo_collection():\n",
        "    \"\"\"Returns the MongoDB collection object.\"\"\"\n",
        "    try:\n",
        "        # print(MONGO_URI)\n",
        "        client = MongoClient(MONGO_URI, server_api=ServerApi('1'))\n",
        "        db = client[DB_NAME]\n",
        "        collection = db[COLLECTION_NAME]\n",
        "\n",
        "        # Check if the collection is empty and populate it\n",
        "        if collection.count_documents({}) == 0:\n",
        "            employees = [\n",
        "                {'id': 1, 'name': 'Alice', 'department': 'Engineering', 'salary': 120000},\n",
        "                {'id': 2, 'name': 'Bob', 'department': 'Sales', 'salary': 90000},\n",
        "                {'id': 3, 'name': 'Charlie', 'department': 'Engineering', 'salary': 150000},\n",
        "                {'id': 4, 'name': 'David', 'department': 'Marketing', 'salary': 85000},\n",
        "                {'id': 5, 'name': 'Eve', 'department': 'Sales', 'salary': 95000},\n",
        "                {'id': 6, 'name': 'Frank', 'department': 'Engineering', 'salary': 130000},\n",
        "            ]\n",
        "            collection.insert_many(employees)\n",
        "            print(\"Employee collection populated with sample data.\")\n",
        "\n",
        "        return collection\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error connecting to MongoDB: {e}\")\n",
        "        return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLkE52EIWTII",
        "outputId": "13acd3ab-3c42-4ad0-95cb-aa31e06a747c"
      },
      "outputs": [],
      "source": [
        "#Run it to populate the data in db and see if its working\n",
        "get_mongo_collection()\n",
        "collection = get_mongo_collection()\n",
        "collection.count_documents({})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "ISdXThZ4Gg-S"
      },
      "outputs": [],
      "source": [
        "# Custom Tool for MongoDB Interaction ---\n",
        "def run_mongo_query(query_json: dict) -> str:\n",
        "  # print(\"in run_mongo_query\")\n",
        "  \"\"\"\n",
        "  This is a custom tool that takes a PyMongo query as a string, executes it,\n",
        "  and returns the result. The LLM will generate a query in a specific format\n",
        "  that we can parse and execute.\n",
        "\n",
        "  Args:\n",
        "      query_string: A string representing a Python expression to query the\n",
        "                    MongoDB collection.\n",
        "                    Example: 'collection.count_documents({\"department\": \"Engineering\"})'\n",
        "                    Another example: 'list(collection.find({\"department\": \"Sales\"}))'\n",
        "\n",
        "  Returns:\n",
        "      A JSON string of the query result or an error message.\n",
        "  \"\"\"\n",
        "  # print(f\"query string {query_json}\")\n",
        "  # return query_string\n",
        "\n",
        "\n",
        "  collection = get_mongo_collection()\n",
        "  if collection is None:\n",
        "      return \"Database connection failed.\"\n",
        "\n",
        "  try:\n",
        "      # print(\"Before execute query\")\n",
        "      # print(query_json)\n",
        "      # print(query_json.get('type'))\n",
        "      # print(query_json.get('collection'))\n",
        "      # print(query_json.get('query'))\n",
        "\n",
        "      if query_json.get('type') == \"count_query\":\n",
        "        # print(\"in count query\")\n",
        "        result = collection.count_documents(query_json.get('query'))\n",
        "      elif query_json.get('type') == \"find_query\":\n",
        "        # print(\"in find query\")\n",
        "        result = list(collection.find(query_json.get('query')))\n",
        "      elif query_json.get('type') == \"aggregator_query\":\n",
        "        # print(\"in aggregator query\")\n",
        "        result = list(collection.aggregate(query_json.get('query')))\n",
        "\n",
        "      # print(\"After execute query\")\n",
        "\n",
        "      # Handle different types of query results\n",
        "      if isinstance(result, (list, dict)):\n",
        "          # Convert results to a JSON string\n",
        "          return json.dumps(result, default=str)\n",
        "      else:\n",
        "          return str(result)\n",
        "\n",
        "  except Exception as e:\n",
        "      return f\"Error executing MongoDB query: {e}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "o06ArkbqP6jL"
      },
      "outputs": [],
      "source": [
        "#Define the prompt ---\n",
        "query_gen_template = \"\"\"\n",
        "You are a skilled MongoDB expert and an expert at converting natural language questions into mongodb query json.\n",
        "\n",
        "The MongoDB collection 'employees' has documents with fields: 'name', 'department', 'salary'.\n",
        "\n",
        "Use the collection name instead of collection in the actual query.\n",
        "\n",
        "You need to provide the collection name as a key in output json on which the query needs to be perform, the actual query in the query key and the type of query like count_query, find_query, aggregator_query.\n",
        "Your final output should be the json string, nothing else.\n",
        "You should only generate the query for read operations, for other operations you can simply deny and give output \"Out of my capacity as of now\"\n",
        "\n",
        "Question: {question}\n",
        "\"\"\"\n",
        "\n",
        "query_gen_prompt = PromptTemplate.from_template(query_gen_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "LmdUMxKNG7oA"
      },
      "outputs": [],
      "source": [
        "# Custom chain to execute the generated query\n",
        "# The RunnableLambda turns our function into a chain component.\n",
        "query_execution_runnable = RunnableLambda(run_mongo_query)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "MzWUiwwoQMVZ"
      },
      "outputs": [],
      "source": [
        "# Final chain to summarize the result\n",
        "final_summary_template = \"\"\"\n",
        "You are a friendly chatbot that answers questions based on a query result.\n",
        "The user asked: {question}\n",
        "The query result was: {query_result}\n",
        "\n",
        "Provide a clear, concise answer.\n",
        "\"\"\"\n",
        "final_summary_prompt = PromptTemplate.from_template(final_summary_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "KH7X_HjgToWL"
      },
      "outputs": [],
      "source": [
        "def print_and_pass(input_data):\n",
        "    \"\"\"Prints the input data and returns it unchanged.\"\"\"\n",
        "    print(\"--- Intermediate Output ---\")\n",
        "    print(input_data)\n",
        "    print(\"-------------------------\")\n",
        "    return input_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "HpQ8xG_xjBNM"
      },
      "outputs": [],
      "source": [
        "def get_actual_query(input_dict):\n",
        "  # print(f\"input dict {input_dict}\")\n",
        "  cleaned_string = input_dict.strip().removeprefix('```json').removesuffix('```').strip()\n",
        "  # print(f\"cleaned string {cleaned_string}\")\n",
        "  # print(f\"json output {json.loads(cleaned_string)}\")\n",
        "  return json.loads(cleaned_string)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "ftIe459GJyBd"
      },
      "outputs": [],
      "source": [
        "llm = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
        "\n",
        "full_chain = (\n",
        "    # Step 1: Start with input\n",
        "    RunnablePassthrough.assign(question=lambda x: x[\"question\"])\n",
        "\n",
        "    # Step 2: Generate parsed query from question\n",
        "    .assign(\n",
        "        parsed_query=(\n",
        "            query_gen_prompt\n",
        "            | llm\n",
        "            | StrOutputParser()\n",
        "            | get_actual_query\n",
        "        )\n",
        "    )\n",
        "\n",
        "    # Step 3: Run MongoDB query\n",
        "    .assign(\n",
        "        query_result=RunnableLambda(lambda x: run_mongo_query(x[\"parsed_query\"]))\n",
        "    )\n",
        "\n",
        "    # Step 4: Summarize results using question & query_result\n",
        "    | final_summary_prompt\n",
        "\n",
        "    # Step 5: Pass to LLM\n",
        "    | llm\n",
        "\n",
        "    # Step 6: Parse final output string\n",
        "    | StrOutputParser()\n",
        "\n",
        "    # | RunnableLambda(print_and_pass)\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IjBe8ggIQ9iO",
        "outputId": "6227035d-bb02-43ff-f39d-9d9267a8b5ed"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You: how many employee are there\n",
            "AI: There are 6 employees.\n",
            "You: what is the total salary of all employee\n",
            "AI: The total salary of all employees is $670,000.\n",
            "You: how many employee are there in Engineering department\n",
            "AI: There are 3 employees in the Engineering department.\n",
            "You: who is the highest paid employee in company\n",
            "AI: The highest paid employee in the company is Charlie from the Engineering department, with a salary of $150,000.\n",
            "You: can you give me count of employees in each department\n",
            "AI: Certainly! Here is the count of employees in each department:\n",
            "\n",
            "- Engineering: 3 employees\n",
            "- Sales: 2 employees\n",
            "- Marketing: 1 employee\n",
            "You: exit\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "  user_query = input(\"You: \")\n",
        "  if user_query.lower() == 'exit':\n",
        "      break\n",
        "\n",
        "  try:\n",
        "      # We now use the `.invoke()` method with a dictionary.\n",
        "      response = full_chain.invoke({\"question\": user_query}, config={\n",
        "          # \"verbose\": True,\n",
        "          # \"callbacks\": [ConsoleCallbackHandler()]\n",
        "          })\n",
        "      print(f\"AI: {response.strip()}\")\n",
        "  except Exception as e:\n",
        "      print(f\"An error occurred: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "8RcSeqTSRBPN"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
